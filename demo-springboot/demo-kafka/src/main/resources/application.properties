
spring.application.name=demo-kafka
server.port=8080

# --- kafka setting
spring.kafka.num-of-partitions=7
spring.kafka.listener.missing-topics-fatal=false
spring.kafka.template.default-topic=kafka-default-topic
spring.kafka.bootstrap-servers=192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092

# --- kafka producer setting

spring.kafka.producer.group-id=kafka-producer
spring.kafka.producer.enable-auto-commit=true
spring.kafka.producer.auto-commit-interval=1000
spring.kafka.producer.max-poll-records=1000
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.properties.sasl.mechanism=PLAIN
spring.kafka.producer.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.producer.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="username" password="password";
#spring.kafka.producer.retries=0
#spring.kafka.producer.batch-size=16384
#spring.kafka.producer.buffer-memory=33554432

# --- kafka consumer setting
spring.kafka.consumer.group-id=kafka-consumer
# commit offset
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=5000ms
#  Consumer每次调用poll()时取到的records的最大数
spring.kafka.consumer.max-poll-records=1000
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.consumer.properties.sasl.mechanism=PLAIN
spring.kafka.consumer.properties.security.protocol=SASL_PLAINTEXT
spring.kafka.consumer.properties.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="username" password="password";
spring.kafka.consumer.auto-offset-reset=latest
